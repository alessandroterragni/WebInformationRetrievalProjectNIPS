{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author collaboration clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The code below will allow to cluster based on authors collaboration, it uses as an input the file \"paper_authors.csv\" with two main columns \"paper_id\" and \"author_id\". Then a graph is created with this relations having the nodes as authors and the links as collaboration. And finally, the MCL clustering algorithm was used to cluster the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define MCL clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: ipykernel_launcher.py [options] <input_matrix>\n",
      "\n",
      "ipykernel_launcher.py: error: no such option: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "from optparse import OptionParser\n",
    "import logging\n",
    "\n",
    "def normalize(A):\n",
    "    column_sums = A.sum(axis=0)\n",
    "    new_matrix = A / column_sums[np.newaxis, :]\n",
    "    return new_matrix\n",
    "\n",
    "def inflate(A, inflate_factor):\n",
    "    return normalize(np.power(A, inflate_factor))\n",
    "\n",
    "def expand(A, expand_factor):\n",
    "    return np.linalg.matrix_power(A, expand_factor)\n",
    "\n",
    "def add_diag(A, mult_factor):\n",
    "    return A + mult_factor * np.identity(A.shape[0])\n",
    "\n",
    "def get_clusters(A):\n",
    "    clusters = []\n",
    "    for i, r in enumerate((A>0).tolist()):\n",
    "        if r[i]:\n",
    "            clusters.append(A[i,:]>0)\n",
    "\n",
    "    clust_map  ={}\n",
    "    for cn , c in enumerate(clusters):\n",
    "        for x in  [ i for i, x in enumerate(c) if x ]:\n",
    "            clust_map[cn] = clust_map.get(cn, [])  + [x]\n",
    "    return clust_map\n",
    "\n",
    "def draw(G, A, cluster_map):\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    clust_map = {}\n",
    "    for k, vals in cluster_map.items():\n",
    "        for v in vals:\n",
    "            clust_map[v] = k\n",
    "\n",
    "    colors = []\n",
    "    for i in range(len(G.nodes())):\n",
    "        colors.append(clust_map.get(i, 100))\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "\n",
    "    from matplotlib.pylab import matshow, show, cm\n",
    "    plt.figure(2)\n",
    "    nx.draw_networkx_nodes(G, pos,node_size = 200, node_color =colors , cmap=plt.cm.Blues )\n",
    "    nx.draw_networkx_edges(G,pos, alpha=0.5)\n",
    "    matshow(A, fignum=1, cmap=cm.gray)\n",
    "    plt.show()\n",
    "    show()\n",
    "\n",
    "\n",
    "def stop(M, i):\n",
    "\n",
    "    if i%5==4:\n",
    "        m = np.max( M**2 - M) - np.min( M**2 - M)\n",
    "        if m==0:\n",
    "            logging.info(\"Stop at iteration %s\" % i)\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def mcl(M, expand_factor = 2, inflate_factor = 2, max_loop = 10 , mult_factor = 1):\n",
    "    M = add_diag(M, mult_factor)\n",
    "    M = normalize(M)\n",
    "\n",
    "    for i in range(max_loop):\n",
    "        logging.info(\"loop\", i)\n",
    "        M = inflate(M, inflate_factor)\n",
    "        M = expand(M, expand_factor)\n",
    "        if stop(M, i): break\n",
    "\n",
    "    clusters = get_clusters(M)\n",
    "    return M, clusters\n",
    "\n",
    "def networkx_mcl(G, expand_factor = 2, inflate_factor = 2, max_loop = 10 , mult_factor = 1):\n",
    "    import networkx as nx\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    return mcl(np.array(A.todense()), expand_factor, inflate_factor, max_loop, mult_factor)\n",
    "\n",
    "def print_info(options):\n",
    "    print(\"-\"*60)\n",
    "    print(\"MARKOV CLUSTERING:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"  expand_factor: %s\" % options.expand_factor)\n",
    "    print(\"  inflate_factor: %s\" % options.inflate_factor)\n",
    "    print(\"  mult factor: %s\" % options.mult_factor)\n",
    "    print(\"  max loops: %s\\n\" % options.max_loop)\n",
    "\n",
    "def get_options():\n",
    "    usage = \"usage: %prog [options] <input_matrix>\"\n",
    "    parser = OptionParser(usage)\n",
    "    parser.add_option(\"-e\", \"--expand_factor\",\n",
    "                      dest=\"expand_factor\",\n",
    "                      default=2,\n",
    "                      type=int,\n",
    "                      help=\"expand factor (default: %default)\")\n",
    "    parser.add_option(\"-i\", \"--inflate_factor\",\n",
    "                      dest=\"inflate_factor\",\n",
    "                      default=2,\n",
    "                      type=float,\n",
    "                      help=\"inflate factor (default: %default)\")\n",
    "    parser.add_option(\"-m\", \"--mult_factor\",\n",
    "                      dest=\"mult_factor\",\n",
    "                      default=2,\n",
    "                      type=float,\n",
    "                      help=\"multiply factor (default: %default)\")\n",
    "    parser.add_option(\"-l\", \"--max_loops\",\n",
    "                      dest=\"max_loop\",\n",
    "                      default=60,\n",
    "                      type=int,\n",
    "                      help=\"max loops (default: %default)\")\n",
    "    parser.add_option(\"-o\", \"--output\", metavar=\"FILE\", \n",
    "                      help=\"output (default: stdout)\")\n",
    "\n",
    "    parser.add_option(\"-v\", \"--verbose\",\n",
    "                      action=\"store_true\", dest=\"verbose\", default=True,\n",
    "                      help=\"verbose (default: %default)\")\n",
    "    parser.add_option(\"-d\", \"--draw-graph\",\n",
    "                      action=\"store_true\", dest=\"draw\", default=False,\n",
    "                      help=\"show graph with networkx (default: %default)\")\n",
    "    \n",
    "\n",
    "    (options, args) = parser.parse_args()\n",
    "\n",
    "    try:\n",
    "        filename = args[0]\n",
    "    except:\n",
    "        raise Exception('input', 'missing input filename')\n",
    "\n",
    "\n",
    "    return options, filename\n",
    "\n",
    "def get_graph(csv_filename):\n",
    "    import networkx as nx\n",
    "\n",
    "    M = []\n",
    "    for r in open(csv_filename):\n",
    "        r = r.strip().split(\",\")\n",
    "        M.append( map( lambda x: float(x.strip()), r))\n",
    "\n",
    "    G = nx.from_numpy_matrix(np.matrix(M))\n",
    "    return np.array(M), G\n",
    "\n",
    "def clusters_to_output(clusters, options):\n",
    "    if options.output and len(options.output)>0:\n",
    "        f = open(options.output, 'w')\n",
    "        for k, v in clusters.items():\n",
    "            f.write(\"%s|%s\\n\" % (k, \", \".join(map(str, v)) ))\n",
    "        f.close()\n",
    "    else:    \n",
    "        print(\"Clusters:\")\n",
    "        for k, v in clusters.items():\n",
    "            print(k, v)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    options, filename = get_options()\n",
    "    print_info(options)\n",
    "    M, G = get_graph(filename)\n",
    "\n",
    "    print(\" number of nodes: %s\\n\" % M.shape[0])\n",
    "\n",
    "    print(time.time(), \"evaluating clusters...\")\n",
    "    M, clusters = networkx_mcl(G, expand_factor = options.expand_factor,\n",
    "                               inflate_factor = options.inflate_factor,\n",
    "                               max_loop = options.max_loop,\n",
    "                               mult_factor = options.mult_factor)\n",
    "    print(time.time(), \"done\\n\")\n",
    "\n",
    "    clusters_to_output(clusters, options)\n",
    "\n",
    "    if options.draw:\n",
    "        print(time.time(), \"drawing...\")\n",
    "        draw(G, M, clusters)\n",
    "        print(time.time(), \"done\")\n",
    "#https://github.com/koteth/python_mcl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read the file \"paper_authors.csv\" and transform the data into a two dimensions list with the pairs of all possible authors collaborating each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  21817\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "d = Path().resolve().parent.parent\n",
    "d = str(d) + \"/data/original/paper_authors.csv\"\n",
    "\n",
    "csv = pd.read_csv(d)\n",
    "#csv = pd.read_csv('paper_authors.csv')\n",
    "paper_id = {}\n",
    "for it in range(0,len(csv)):\n",
    "    num = csv['paper_id'][it]\n",
    "    if num in paper_id:\n",
    "        paper_id[num].append(csv['author_id'][it])\n",
    "    else:\n",
    "        paper_id[num] = []\n",
    "        paper_id[num].append(csv['author_id'][it])\n",
    "lista = []\n",
    "for it in paper_id.items():\n",
    "    if(len(it[1])>=2):\n",
    "        au_paper = 0\n",
    "        for au in range(0,len(it[1])-1):\n",
    "            for au2 in range(au+1,len(it[1])):\n",
    "                x = [it[1][au],it[1][au2]]\n",
    "                lista.append(x)\n",
    "\n",
    "print(\"Number of rows: \",len(lista))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove duplicates in collaboration, so its ensure to have unique author pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Remove duplicates\n",
    "newListaF = sorted(lista)\n",
    "listaFinal = [newListaF[i] for i in range(len(newListaF)) if i==0 or newListaF[i] != newListaF[i-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list of unique authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 1. Get the list of unique nodes in the graph\n",
    "flist=[]\n",
    "for x in listaFinal:\n",
    "    for y in range(2):\n",
    "        if x[y] not in flist:\n",
    "            flist.append(x[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create graph of authors with library \"networkx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  8457\n",
      "Number of edges:  18451\n"
     ]
    }
   ],
   "source": [
    "#Graph creation\n",
    "G=nx.Graph(name=\"Authors graph\")\n",
    "G.add_edges_from(listaFinal)\n",
    "\n",
    "print(\"Number of nodes: \",G.number_of_nodes())\n",
    "print(\"Number of edges: \",G.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create clusters using the algorithm MCL clustering, the input is the graph from networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#As smaller the inflation as bigger the size of the clusters\n",
    "M, clusters = networkx_mcl(G,inflate_factor=1.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The relation between author and cluster is made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 2. Assign the node to each cluster\n",
    "fclusters={}\n",
    "for x in clusters:\n",
    "    #print(clusters[x])\n",
    "    fclusters[flist[x]] = clusters[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusters are being name, with format \"Cluster[No.]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 3. Assign to each node the cluster name in format \"Cluster[No.]\"\n",
    "d = fclusters\n",
    "set_dict = list(enumerate(set(tuple(i) for i in d.values()), 1)) \n",
    "final_dict = { k: 'Cluster' + str([i for i,j in set_dict if list(j) == v][0]) for k,v in d.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a CSV file with the final result, a table with columns \"author_id\" and \"cluster_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the dictionary as CSV\n",
    "import csv\n",
    "w = csv.writer(open(\"output_support.csv\", \"w\"))\n",
    "for key, val in final_dict.items():\n",
    "    w.writerow([key, val])\n",
    "with open('output_support.csv') as input, open('author-collaboration-clustering.csv', 'w') as output:\n",
    "    non_blank = (line for line in input if line.strip())\n",
    "    output.writelines(non_blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Function to evaluate the graph and the similarity among authors, with SimRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Chose relevant inflate factor\n",
    "#Compute the SimRank between nodes from the same cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "def simrank(G, r=0.9, max_iter=100):\n",
    "    # init. vars\n",
    "    sim_old = defaultdict(list)\n",
    "    sim = defaultdict(list)\n",
    "    for n in G.nodes():\n",
    "        sim[n] = defaultdict(int)\n",
    "        sim[n][n] = 1\n",
    "        sim_old[n] = defaultdict(int)\n",
    "        sim_old[n][n] = 0\n",
    "\n",
    "    # recursively calculate simrank\n",
    "    for iter_ctr in range(max_iter):\n",
    "        if _is_converge(sim, sim_old):\n",
    "            break\n",
    "        sim_old = copy.deepcopy(sim)\n",
    "        for u in G.nodes():\n",
    "            for v in G.nodes():\n",
    "                if u == v:\n",
    "                    continue\n",
    "                s_uv = 0.0\n",
    "                for n_u in G.neighbors(u):\n",
    "                    for n_v in G.neighbors(v):\n",
    "                        s_uv += sim_old[n_u][n_v]\n",
    "                sim[u][v] = (r * s_uv / (len(G.neighbors(u)) * len(G.neighbors(v))))\n",
    "    return sim\n",
    "\n",
    "def _is_converge(s1, s2, eps=1e-4):\n",
    "    for i in s1.keys():\n",
    "        for j in s1[i].keys():\n",
    "            if abs(s1[i][j] - s2[i][j]) >= eps:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#simrank(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of how simrank works and the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'a': defaultdict(int,\n",
       "                         {'a': 1,\n",
       "                          'b': 0.653792211016936,\n",
       "                          'c': 0.6260762680740787,\n",
       "                          'd': 0.7317028881451203}),\n",
       "             'b': defaultdict(int,\n",
       "                         {'a': 0.653792211016936,\n",
       "                          'b': 1,\n",
       "                          'c': 0.6260762680740787,\n",
       "                          'd': 0.7317028881451203}),\n",
       "             'c': defaultdict(int,\n",
       "                         {'a': 0.6260762680740789,\n",
       "                          'b': 0.6260762680740789,\n",
       "                          'c': 1,\n",
       "                          'd': 0.5365354388877558}),\n",
       "             'd': defaultdict(int,\n",
       "                         {'a': 0.7317028881451202,\n",
       "                          'b': 0.7317028881451202,\n",
       "                          'c': 0.5365354388877557,\n",
       "                          'd': 1})})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import networkx\n",
    "#import networkx_addon\n",
    "G1 = nx.Graph()\n",
    "G1.add_edges_from([('a','b'), ('b','c'), ('a','c'), ('c','d')])\n",
    "simrank(G1)\n",
    "#s = networkx_addon.similarity.simrank(G1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
